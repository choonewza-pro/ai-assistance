{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "531b4263-17ed-4c30-ab8e-acab1f5e93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain-text-splitters\n",
    "# !pip install langchain-chroma\n",
    "# !pip install -U langchain-ollama\n",
    "# !pip install -U pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fac200ef-bc99-4526-a2d1-e99bbab7a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pythainlp\n",
      "  Downloading pythainlp-5.0.5-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.11/site-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2023.7.22)\n",
      "Downloading pythainlp-5.0.5-py3-none-any.whl (17.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pythainlp\n",
      "Successfully installed pythainlp-5.0.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install pythainlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46fc4eac-2207-4965-bb8b-018db3b492a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ตั้งค่าให้ Ollama ใช้เซิร์ฟเวอร์ที่รันอยู่บนเครื่องอื่น\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "\n",
    "# ตรวจสอบว่าตัวแปรถูกตั้งค่าแล้วหรือไม่\n",
    "print(os.getenv(\"USER_AGENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee8016d0-3134-4580-ba41-d2d7824c342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'http://ollama:11434'}, page_content='Ollama is running')]\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Monkey Patch requests.get เพื่อใส่ User-Agent\n",
    "original_get = requests.get\n",
    "\n",
    "def patched_get(url, *args, **kwargs):\n",
    "    headers = kwargs.pop(\"headers\", {})\n",
    "    headers[\"User-Agent\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "    return original_get(url, headers=headers, *args, **kwargs)\n",
    "\n",
    "requests.get = patched_get  # ใช้ patched version ของ requests.get\n",
    "\n",
    "# ใช้ WebBaseLoader ตามปกติ\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"http://ollama:11434\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# คืนค่า requests.get กลับเป็นปกติ (ถ้าต้องการ)\n",
    "requests.get = original_get\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c61705e3-7b9e-410f-bf4b-d7c27f3008c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edaaefdb-b400-4a69-8c74-711244489c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ollama:11434\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ตั้งค่าให้ Ollama ใช้เซิร์ฟเวอร์ที่รันอยู่บนเครื่องอื่น\n",
    "os.environ[\"OLLAMA_BASE_URL\"] = \"http://ollama:11434\"\n",
    "\n",
    "# ตรวจสอบว่าตัวแปรถูกตั้งค่าแล้วหรือไม่\n",
    "print(os.getenv(\"OLLAMA_BASE_URL\"))  # ควรแสดง http://server-ip:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0d42ee3-352c-4f95-839b-42ff78eba240",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://ollama:11434\"\n",
    "OLLAMA_LLM_MODEL = \"deepseek-r1:8b\"\n",
    "OLLAMA_EMBED_MODEL = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbfdb1e3-a1f8-43fd-8ee1-d8509c912f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa2b9773-f136-4ab8-9e21-805802501c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "def ingest(file_path: str):\n",
    "    chunk_size = 500\n",
    "    db_path = \"./sql_chroma_db\"\n",
    "    # Delete the folder if it exists\n",
    "    if os.path.exists(db_path):\n",
    "        shutil.rmtree(db_path)\n",
    "        print(f\"Deleted existing folder: {db_path}\")\n",
    "\n",
    "    # Add a 1-second delay before loading the PDF\n",
    "    time.sleep(3)\n",
    "        \n",
    "    # Get the doc\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "    \n",
    "    # Split the pages by char\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    \n",
    "    print(f\"Split {len(pages)} documents into {len(chunks)} chunks.\")\n",
    "    \n",
    "    \n",
    "    local_embeddings = OllamaEmbeddings(\n",
    "        model=OLLAMA_EMBED_MODEL,\n",
    "        base_url=OLLAMA_BASE_URL,\n",
    "    )\n",
    "    \n",
    "    # Create vector store\n",
    "    Chroma.from_documents(\n",
    "        documents=chunks,  \n",
    "        embedding=local_embeddings, \n",
    "        collection_name=\"thai_docs\",\n",
    "        persist_directory=db_path,\n",
    "        collection_metadata={\n",
    "            \"language\": \"thai\",\n",
    "            \"chunk_size\": chunk_size\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16b9e836-3df3-4fd4-886c-af8d41bcd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing folder: ./sql_chroma_db\n",
      "Split 9 documents into 44 chunks.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# only run this once to generate vector store\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ingest(\"sql_tutorial.pdf\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlaw.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 40\u001b[0m, in \u001b[0;36mingest\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m local_embeddings \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m=\u001b[39mOLLAMA_EMBED_MODEL,\n\u001b[1;32m     36\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mOLLAMA_BASE_URL,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Create vector store\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthai_docs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:299\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/models/Collection.py:344\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m upsert_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_upsert_request(\n\u001b[1;32m    336\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    337\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    342\u001b[0m )\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muris\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:24\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/api/segment.py:564\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris, tenant, database)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record_set(coll, records_to_submit)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quota_enforcer\u001b[38;5;241m.\u001b[39menforce(\n\u001b[1;32m    555\u001b[0m     action\u001b[38;5;241m=\u001b[39mAction\u001b[38;5;241m.\u001b[39mUPSERT,\n\u001b[1;32m    556\u001b[0m     tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    562\u001b[0m )\n\u001b[0;32m--> 564\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_producer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_to_submit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/chromadb/db/mixins/embeddings_queue.py:243\u001b[0m, in \u001b[0;36mSqlEmbeddingsQueue.submit_embeddings\u001b[0;34m(self, collection_id, embeddings)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001b[39;00m\n\u001b[1;32m    242\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RETURNING seq_id, id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pypika doesn't support RETURNING\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m results \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mexecute(sql, params)\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Reorder the results\u001b[39;00m\n\u001b[1;32m    245\u001b[0m seq_ids \u001b[38;5;241m=\u001b[39m [cast(SeqId, \u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    246\u001b[0m     results\n\u001b[1;32m    247\u001b[0m )  \u001b[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "# only run this once to generate vector store\n",
    "# ingest(\"sql_tutorial.pdf\")\n",
    "\n",
    "ingest(\"law.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "362b3c4f-808e-490c-bf60-ec5993cbce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "import pythainlp\n",
    "\n",
    "def create_thai_embeddings(documents, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Create embeddings for Thai text documents and store in Chroma\n",
    "    \n",
    "    Parameters:\n",
    "    documents (list): List of Thai text documents\n",
    "    chunk_size (int): Size of text chunks for splitting\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Configure text splitter for Thai\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # 2. Split documents\n",
    "    texts = text_splitter.create_documents(documents)\n",
    "    \n",
    "    # 3. Configure Ollama embeddings\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"nomic-embed-text\",  # หรือใช้ mistral ก็ได้\n",
    "        base_url=OLLAMA_BASE_URL,\n",
    "        model_kwargs={\n",
    "            \"temperature\": 0.0,  # ให้ผลลัพธ์คงที่\n",
    "            \"num_ctx\": 2048,     # ความยาวบริบทสูงสุด\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 4. Create and configure Chroma\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        collection_name=\"thai_docs\",\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        collection_metadata={\n",
    "            \"language\": \"thai\",\n",
    "            \"chunk_size\": chunk_size\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "# documents = [\n",
    "#     \"เอกสารภาษาไทยฉบับที่ 1\",\n",
    "#     \"เอกสารภาษาไทยฉบับที่ 2\"\n",
    "# ]\n",
    "\n",
    "# vectorstore = create_thai_embeddings(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9099bc-d7cb-4d10-92aa-7cedeb5bb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG chain that retreives relevent chunks and prepares a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16b2ce4b-a575-4042-874b-1bfd6517195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain():\n",
    "    model = OllamaLLM(\n",
    "        model=OLLAMA_LLM_MODEL,\n",
    "        base_url=OLLAMA_BASE_URL\n",
    "    )\n",
    "    \n",
    "    #Load vector store\n",
    "    embedding = OllamaEmbeddings(\n",
    "        model=OLLAMA_EMBED_MODEL,\n",
    "        base_url=OLLAMA_BASE_URL\n",
    "    )\n",
    "    vector_store = Chroma(persist_directory=\"./sql_chroma_db\", embedding_function=embedding)\n",
    "\n",
    "    #Create chain\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        # search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            # \"score_threshold\": 0.7, # คืนค่าเอกสารที่มีคะแนนความคล้ายคลึง ≥ 0.7\n",
    "            # \"fetch_k\": 10,  # ดึงผลลัพธ์มา 10 รายการก่อนเลือก 3 รายการที่หลากหลายที่สุด\n",
    "            # \"lambda_mult\": 0.5,  # ปรับสมดุลระหว่างความคล้ายคลึงและความหลากหลาย\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # # Get documents from the vector store\n",
    "    # results = retriever.invoke(\"ถ้าต้องถูกทำงานล่วงเวลาในวันหยุด เราจะได้ค่าจ้างเท่าไหร?\")\n",
    "    \n",
    "    # # Print the results to see what documents are returned\n",
    "    # print(\"Vector Store Results:\")\n",
    "    # for idx, result in enumerate(results):\n",
    "    #     print(f\"Result {idx+1}: {result}\")\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        <s> [Instructions] You are a friendly assistant. Answer the question based only on the following context. \n",
    "        If you don't know the answer, then reply, No Context availabel for this question {input}. [/Instructions] </s> \n",
    "        [Instructions] Question: {input}\n",
    "        Context: {context} \n",
    "        Answer: [/Instructions]\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(model, prompt)\n",
    "    chain = create_retrieval_chain(retriever, document_chain)\n",
    "    \n",
    "    return chain, prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a78a8fa4-06bf-4be3-8efd-1d7c31c8be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str):\n",
    "    # Initialize chain and prompt\n",
    "    chain, prompt = rag_chain()\n",
    "\n",
    "    # Display the prompt before invoking\n",
    "    print(\"Prompt used in the chain:\")\n",
    "    print(prompt.format(input=query, context=\"\"))\n",
    "\n",
    "    # Invoke chain with the query\n",
    "    result = chain.invoke({\"input\": query})\n",
    "\n",
    "    # Print the result\n",
    "    print(\"Answer: \", result[\"answer\"])\n",
    "    \n",
    "    # Show the source documents\n",
    "    for doc in result[\"context\"]:\n",
    "        print(\"Source: \", doc.metadata[\"source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fddab790-b2a5-43d7-86af-dcbf9ea0ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Answer the question according to the context given very briefly:\n",
      "           Question: ไม่สามารถรับเด็กอายุต่ำกว่ากี่ปีให้มาทำงานได้?.\n",
      "           Context: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "#Load vector store\n",
    "embedding = OllamaEmbeddings(\n",
    "      model=OLLAMA_EMBED_MODEL,\n",
    "    base_url=OLLAMA_BASE_URL\n",
    ")\n",
    "vector_store = Chroma(persist_directory=\"./sql_chroma_db\", embedding_function=embedding)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "     search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"lambda_mult\": 0.8\n",
    "         \n",
    "     },\n",
    ")\n",
    "\n",
    "question = \"ไม่สามารถรับเด็กอายุต่ำกว่ากี่ปีให้มาทำงานได้?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "context = ' '.join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Answer the question according to the context given very briefly:\n",
    "           Question: {question}.\n",
    "           Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "page_contents = []\n",
    "for doc in retrieved_docs:\n",
    "    try:\n",
    "         print(doc.page_content)\n",
    "         print(\"------------------\")\n",
    "    except AttributeError:\n",
    "        print(f\"Document missing 'page_content': {doc}\") # หรือจะข้ามไปเลยก็ได้\n",
    "print(page_contents)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4190474-05d7-4cf9-98f5-c289ef3ae7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, let me try to figure this out. The question is asking what the minimum age is for a child to be able to work according to the given context.\n",
      "\n",
      "First, I'll read through the context provided. It talks about overtime, notice periods, labor contracts without specific durations, and termination procedures. Then it moves on to cases where an employer and employee can terminate the contract mutually.\n",
      "\n",
      "Next, there's a part discussing protective measures for child workers. It mentions that young workers have rights to leave for training organized by the Department of Labor, and employers must allow this leave with overtime pay equivalent to regular days. This seems relevant because it directly refers to child workers' rights regarding work hours and leave.\n",
      "\n",
      "Then, it lists situations where a worker loses their ability to work due to accidents or diseases. Points (j), (k), and (l) detail conditions under which an employee can't work anymore. These include intoxication, simple labor that doesn't require precise measurement, monitoring security locations or assets, and remote work where the environment makes time management difficult.\n",
      "\n",
      "Finally, it discusses working on holidays. There are two scenarios: if a child worker has the right to receive overtime pay when they work on a holiday, or if they don't have such rights.\n",
      "\n",
      "Putting this together, the context is about labor regulations, including those protecting child workers from excessive overtime and ensuring they can take leave for training. However, it also outlines situations where an employee might lose their job due to various reasons, including health issues or performance problems.\n",
      "\n",
      "The question specifically asks about the minimum age for a child to work. From the context, there's no explicit mention of a specific age limit. Instead, it focuses on labor protections and conditions rather than the age itself.\n",
      "\n",
      "So, based on the information given, I can't determine the exact minimum age from the context provided. It seems that the focus is more on the rights related to work hours and leaves rather than the age requirement.\n",
      "</think>\n",
      "\n",
      "จากข้อมูลที่ให้ไว้ในคонт์เท็กซ์ไม่มีการกล่าวถึงอายุเป็นเลขเชิงนับวันหรือเลขตัวสำหรับการทำงานของเด็กอายุ ตัวอย่างคุยก่อนการเลิกสัญญาและคุณสมบัติการทํางานในวันหยุด นอกจากนี้ยังเกี่ยวข้องกับสิทธิการลาเพื่อการศึกษาหรืออบรมให้แก่ลูกจ้างเด็ก ซึ่งไม่ได้ใหข้อมูลเกี่ยวกับอายุ minimum ที่ต้องมีในการทำงาน\n",
      "\n",
      "**คำตอบ:**\n",
      "จากคонт์เท็กซ์ไม่สามารถหาผู้วัยต่ำกว่าอายุหนึ่งที่กำหนดไว้ในคонт์เท็กซ์ได้\n"
     ]
    }
   ],
   "source": [
    "model = OllamaLLM(\n",
    "    model=OLLAMA_LLM_MODEL,\n",
    "    base_url=OLLAMA_BASE_URL\n",
    ")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb9a20-cde4-4b12-b00d-8bc1908f1b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
